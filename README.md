# Machine-Learning-101

## üíª Proceso de instalaci√≥n
Vamos a utilizar Python. Lo siguiente probablemente ya lo sep√°is si hab√©is usado `conda` para otros m√≥dulos, ¬°pero nunca est√° de m√°s!

Lo primero es instalar [Miniconda](https://docs.anaconda.com/miniconda/install/) .
Yo lo he hecho en Windows con el instalador `.exe`, pero pod√©is seguir las instrucciones para instalarlo desde PowerShell (Windows)
o desde la terminal de Linux o MacOS.

He incluido un archivo [requirements.txt](requirements.txt).
Haced `git clone` de este repositorio, entrad (`cd`) desde PowerShell/terminal y ejecutad:
```shell
conda create -n KCML python=3.12
conda install --name KCML --file .\requirements.txt
conda activate KCML
```
El nombre `KCML` pod√©is cambiarlo, es s√≥lo el que le he dado yo.

Por √∫ltimo, ejecutad `jupyter lab`.

## üéì Diapositivas

[0. Presentaci√≥n y requisitos previos](0.%20Presentaci√≥n%20y%20requisitos%20previos.pdf)

[1. Fundamentos de Machine Learning](1.%20Fundamentos%20de%20Machine%20Learning.pdf)

[2. Regularizaci√≥n](2.%20Regularizaci√≥n.pdf)

[3. Selecci√≥n de caracter√≠sticas](3.%20Selecci√≥n%20de%20caracter√≠sticas.pdf)

[4. √Årboles de decisi√≥n](4.%20√Årboles%20de%20decisi√≥n.pdf)

[5. Bagging y Random Forest](5.%20Bagging%20y%20Random%20Forest.pdf)

[6. Boosted Trees](6.%20Boosted%20Trees.pdf)

[7. SVMs y M√©todos Kernel](7.%20SVMs%20y%20M√©todos%20Kernel.pdf)

[8. M√©tricas](8.%20M√©tricas.pdf)

## üìö Notebooks
Hace falta tener `utils.py`, `data/` y `figuras/` en el mismo directorio.

[1. Fundamentos de Machine Learning](1.%20Fundamentos%20de%20Machine%20Learning.ipynb)

[2. Regularizaci√≥n](2.%20Regularizaci√≥n.ipynb)

[3. Selecci√≥n de caracter√≠sticas](3%20Selecci√≥n%20de%20caracter√≠sticas.ipynb)

[3.1 Consejos para la pr√°ctica](3.1%20Ayuda%20para%20la%20pr√°ctica_%20an√°lisis%20exploratorio.ipynb)

[4. √Årboles de decisi√≥n](4.%20√Årboles%20de%20decisi√≥n.ipynb)

[5. Bagging y Random Forest](5.%20Bagging%20y%20Random%20Forest.ipynb)

[6. Boosted Trees](6.%20Boosted%20Trees.ipynb)

[6.1 Boosting - Otras implementaciones](6.1%20Boosting%20-%20Otras%20implementaciones.ipynb)

[7. SVMs y M√©todos Kernel](7.%20SVMs%20y%20M√©todos%20Kernel.ipynb)

[8. M√©tricas](8.%20M√©tricas.ipynb)

[9. Casos pr√°cticos](9.%20Casos%20pr√°cticos.ipynb)

## üìñ Notebooks con soluciones üïØ
[1. Fundamentos de Machine Learning](1.%20Fundamentos%20de%20Machine%20Learning-Soluciones.ipynb)

[2. Regularizaci√≥n](2.%20Regularizaci√≥n-Soluciones.ipynb)

[3. Selecci√≥n de caracter√≠sticas](3%20Selecci√≥n%20de%20caracter√≠sticas-Soluciones.ipynb)

[3.1 Consejos para la pr√°ctica](3.1%20Ayuda%20para%20la%20pr√°ctica_%20an√°lisis%20exploratorio-Soluciones.ipynb)

[4. √Årboles de decisi√≥n](4.%20√Årboles%20de%20decisi√≥n-Soluciones.ipynb)

[5. Bagging y Random Forest](5.%20Bagging%20y%20Random%20Forest-Soluciones.ipynb)

[6. Boosted Trees](6.%20Boosted%20Trees-Soluciones.ipynb)

[6.1 Boosting - Otras implementaciones](6.1%20Boosting%20-%20Otras%20implementaciones-Soluciones.ipynb)

[7. SVMs y M√©todos Kernel](7.%20SVMs%20y%20M√©todos%20Kernel-Soluciones.ipynb)


## üë∑‚Äç‚ôÄÔ∏è Proyecto üë∑‚Äç‚ôÇÔ∏è
Comprimido en `.zip` [aqu√≠](Proyecto.zip). Contiene el enunciado en pdf y 60MB de datos.
